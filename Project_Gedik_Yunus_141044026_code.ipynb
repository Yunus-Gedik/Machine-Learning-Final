{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_proje.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBoFqKs5qqf3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import statistics\n",
        "from statistics import mode\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "def my_model(nodes, attr_count, loss):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=attr_count, activation='relu'))\n",
        "    model.add(Dense(nodes, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile the keras model\n",
        "    model.compile(loss=loss, optimizer='adam')\n",
        "    # model.compile(loss='mean_absolute_error', optimizer='adam', metrics=[metrics.mean_absolute_error])\n",
        "    return model\n",
        "\n",
        "def perform(csv_name,seperator,predict_class,loss):\n",
        "    data = pd.read_csv(csv_name, sep=seperator)\n",
        "\n",
        "    predict = predict_class\n",
        "\n",
        "    # Divide data into train and test splits\n",
        "    X = np.array(data.drop([predict], 1))\n",
        "    Y = np.array(data[predict])\n",
        "    x_train,x_test,y_train,y_test = sklearn.model_selection.train_test_split( X,Y, test_size=0.1 )\n",
        "\n",
        "\n",
        "    model = my_model(5,data.drop([predict], 1).columns.size,loss)\n",
        "\n",
        "    model.fit(x_train, y_train, epochs=4, batch_size=10)\n",
        "\n",
        "    t = \"Accuracy is \"\n",
        "    if loss == 'mean_absolute_error':\n",
        "        t = \"Mean Absolute Error is \"\n",
        "\n",
        "    print(t, model.evaluate(x_test, y_test, batch_size=16))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Split the data based on an attribute and an attribute value\n",
        "def test_split(i, value, data):\n",
        "    right = []\n",
        "    left = []\n",
        "    for row in data:\n",
        "        if row[i] >= value:\n",
        "            right.append(row)\n",
        "        else:\n",
        "            left.append(row)\n",
        "    return left, right\n",
        "\n",
        "\n",
        "# Calculate the Gini index for a split dataset\n",
        "def gini_index(groups, categories):\n",
        "    # calculate number of instances on 'this' node\n",
        "    total_count = 0.0\n",
        "    for sub in groups:\n",
        "        total_count += len(sub)\n",
        "\n",
        "    # Gini index (weighted)\n",
        "    gini_score = 0.0\n",
        "    for group in groups:\n",
        "        size = float(len(group))\n",
        "        if size != 0.0:\n",
        "            score = 0.0\n",
        "            for categ_val in categories:\n",
        "                p = [row[-1] for row in group].count(categ_val) / size\n",
        "                score += math.pow(p, 2)\n",
        "            gini_score += (size / total_count) * (1.0 - score)\n",
        "\n",
        "    return gini_score\n",
        "\n",
        "\n",
        "# Select the best split point for a dataset\n",
        "def splitter(data):\n",
        "    categ_values = list(set(row[-1] for row in data))\n",
        "    # Keep track of best gini score row\n",
        "    best_index = -1\n",
        "    best_value = -1\n",
        "    best_score = 1\n",
        "    left_right = None\n",
        "\n",
        "    for index in range(len(data[0]) - 1):\n",
        "        for row in data:\n",
        "            categories = test_split(index, row[index], data)\n",
        "\n",
        "            gini_score = gini_index(categories, categ_values)\n",
        "            if best_score > gini_score:\n",
        "                best_index, best_value, best_score, left_right = index, row[index], gini_score, categories\n",
        "\n",
        "    # Return a dictionary consist of best gini score attribute value, left and right sets and index of that attribute\n",
        "    return {'index': best_index, 'value': best_value, 'categories': left_right}\n",
        "\n",
        "\n",
        "# Convert a node into a leaf. Normally a node is a dictionary but this function transforms a dict into a value.\n",
        "# I later use this utility to differentiate a leaf node from others.\n",
        "def to_terminal(group):\n",
        "    target_values = [row[-1] for row in group]\n",
        "    try:\n",
        "        return mode(target_values)\n",
        "    except statistics.StatisticsError:\n",
        "        # A bad split happened unfortunately. In result of it, count of categories are equal! So I return the first one.\n",
        "        return target_values[0]\n",
        "\n",
        "\n",
        "# Create child splits for a node or make terminal\n",
        "def birth(node, max_depth, min_size, current_depth):\n",
        "    # Pull child nodes' info from parent.\n",
        "    left, right = node['categories']\n",
        "    del (node['categories'])\n",
        "\n",
        "\n",
        "    # BASE CASES\n",
        "\n",
        "    # If there is only 1 child\n",
        "    if not left:\n",
        "        node['left'] = to_terminal(right)\n",
        "        node['right'] = to_terminal(right)\n",
        "        return\n",
        "    elif not right:\n",
        "        node['left'] = to_terminal(left)\n",
        "        node['right'] = to_terminal(left)\n",
        "        return\n",
        "\n",
        "    # Check if I hit max depth\n",
        "    if current_depth >= max_depth:\n",
        "        node['left'] = to_terminal(left)\n",
        "        node['right'] = to_terminal(right)\n",
        "        return\n",
        "\n",
        "\n",
        "    # RECURSIVE CASES\n",
        "\n",
        "    # process right child\n",
        "    if len(right) > min_size:\n",
        "        node['right'] = splitter(right)\n",
        "        birth(node['right'], max_depth, min_size, current_depth + 1)\n",
        "    else:\n",
        "        node['right'] = to_terminal(right)\n",
        "\n",
        "    # process left child\n",
        "    if len(left) > min_size:\n",
        "        node['left'] = splitter(left)\n",
        "        birth(node['left'], max_depth, min_size, current_depth + 1)\n",
        "    else:\n",
        "        node['left'] = to_terminal(left)\n",
        "\n",
        "\n",
        "def print_tree(node, attributes, depth=0):\n",
        "    if isinstance(node, dict):\n",
        "        print('%s[%s < %.3f]' % (depth * ' ', attributes[node['index']], node['value']))\n",
        "        print_tree(node['left'], attributes,depth + 1)\n",
        "        print_tree(node['right'], attributes,depth + 1)\n",
        "    else:\n",
        "        print('%s[%s]' % (depth * ' ', node))\n",
        "\n",
        "\n",
        "# Tree builder\n",
        "def build_tree(train, max_depth, min_size):\n",
        "    root = splitter(train)\n",
        "    birth(root, max_depth, min_size, current_depth=1)\n",
        "    return root\n",
        "\n",
        "\n",
        "# Predict 1 data\n",
        "def predict_one(dt, X):\n",
        "    if X[dt['index']] < dt['value']:\n",
        "        # If not a leaf, i.e terminal node\n",
        "        if isinstance(dt['left'], dict):\n",
        "            return predict_one(dt['left'], X)\n",
        "        else:\n",
        "            return dt['left']\n",
        "    else:\n",
        "        # If not a leaf, i.e terminal node\n",
        "        if isinstance(dt['right'], dict):\n",
        "            return predict_one(dt['right'], X)\n",
        "        else:\n",
        "            return dt['right']\n",
        "\n",
        "\n",
        "# Predict all\n",
        "def predict_dt(dt, X, options):\n",
        "    predictions = list()\n",
        "    for row in X:\n",
        "        prediction = predict_one(dt, row)\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# Build tree with gini\n",
        "def build_dt(X, y, options):\n",
        "    # I used options as a dict to be able to fetch these parameters.\n",
        "    max_depth = options['max_depth']\n",
        "    min_size = options['min_size']\n",
        "\n",
        "    # Concatenate train and target lists to fetch to function.\n",
        "    temp = np.column_stack((X, y))\n",
        "\n",
        "    return build_tree(temp, max_depth, min_size)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcq8XnSQQ8VD",
        "outputId": "4f5aac3e-590f-44a5-db95-f0f392990cb0"
      },
      "source": [
        "# Decision tree for divorce.csv\n",
        "data = pd.read_csv(\"divorce.csv\", sep=\";\")\n",
        "\n",
        "predict = \"Class\"\n",
        "\n",
        "# Divide data into train and test splits\n",
        "X = np.array(data.drop([predict], 1))\n",
        "Y = np.array(data[predict])\n",
        "x_train,x_test,y_train,y_test = sklearn.model_selection.train_test_split( X,Y, test_size=0.1 )\n",
        "\n",
        "options = {'max_depth': 10, 'min_size': 5, 'data':data}\n",
        "\n",
        "my_tree = build_dt(x_train, y_train, options)\n",
        "print_tree(my_tree,data.columns,0)\n",
        "\n",
        "\n",
        "predicted = predict_dt(my_tree,x_test,None)\n",
        "\n",
        "print()\n",
        "print(\"My decision tree \")\n",
        "print(\"Real values:\")\n",
        "print(y_test)\n",
        "print(\"Predicted values:\")\n",
        "print(predicted)\n",
        "\n",
        "\n",
        "rforest = RandomForestClassifier(n_estimators=100)\n",
        "rforest = rforest.fit(x_train,y_train)\n",
        "\n",
        "print()\n",
        "acc = rforest.score(x_test,y_test)\n",
        "print(\"Random Forest score \", acc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Atr18 < 2.000]\n",
            " [Atr26 < 2.000]\n",
            "  [Atr40 < 3.000]\n",
            "   [Atr1 < 0.000]\n",
            "    [0]\n",
            "    [0]\n",
            "   [1]\n",
            "  [1]\n",
            " [Atr1 < 2.000]\n",
            "  [1]\n",
            "  [Atr1 < 2.000]\n",
            "   [1]\n",
            "   [1]\n",
            "\n",
            "My decision tree \n",
            "Real values:\n",
            "[1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1]\n",
            "Predicted values:\n",
            "[1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1]\n",
            "\n",
            "Random Forest score  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT5XpVchQ_NT",
        "outputId": "04110045-3778-484c-ea24-d729f6f903a1"
      },
      "source": [
        "# Decision tree for forecast.csv\n",
        "data = pd.read_csv(\"forecast.csv\", sep=\";\")\n",
        "\n",
        "predict = \"Target (Total orders)\"\n",
        "\n",
        "# Divide data into train and test splits\n",
        "X = np.array(data.drop([predict], 1))\n",
        "Y = np.array(data[predict])\n",
        "x_train,x_test,y_train,y_test = sklearn.model_selection.train_test_split( X,Y, test_size=0.1 )\n",
        "\n",
        "options = {'max_depth': 10, 'min_size': 5, 'data':data}\n",
        "\n",
        "my_tree = build_dt(x_train, y_train, options)\n",
        "print_tree(my_tree,data.columns,0)\n",
        "\n",
        "\n",
        "predicted = predict_dt(my_tree,x_test,None)\n",
        "print()\n",
        "print(\"Real values:\")\n",
        "print(y_test)\n",
        "print(\"Predicted values:\")\n",
        "print(predicted)\n",
        "print()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Non-urgent order < 218.856]\n",
            " [Non-urgent order < 170.566]\n",
            "  [Non-urgent order < 118.552]\n",
            "   [Non-urgent order < 89.526]\n",
            "    [129.412]\n",
            "    [Non-urgent order < 96.494]\n",
            "     [202.02200000000002]\n",
            "     [233.12599999999998]\n",
            "   [Non-urgent order < 148.139]\n",
            "    [Non-urgent order < 130.465]\n",
            "     [Non-urgent order < 120.629]\n",
            "      [235.59799999999998]\n",
            "      [Non-urgent order < 123.143]\n",
            "       [402.60699999999997]\n",
            "       [Non-urgent order < 123.286]\n",
            "        [231.035]\n",
            "        [236.304]\n",
            "     [Non-urgent order < 134.425]\n",
            "      [255.06099999999998]\n",
            "      [Non-urgent order < 144.124]\n",
            "       [213.50900000000001]\n",
            "       [263.043]\n",
            "    [Non-urgent order < 150.257]\n",
            "     [238.826]\n",
            "     [268.64]\n",
            "  [Non-urgent order < 172.783]\n",
            "   [308.178]\n",
            "   [Non-urgent order < 178.433]\n",
            "    [253.847]\n",
            "    [Non-urgent order < 206.206]\n",
            "     [Non-urgent order < 193.768]\n",
            "      [281.42]\n",
            "      [336.87199999999996]\n",
            "     [298.459]\n",
            " [Non-urgent order < 235.106]\n",
            "  [363.402]\n",
            "  [Non-urgent order < 275.076]\n",
            "   [346.035]\n",
            "   [416.83]\n",
            "\n",
            "Real values:\n",
            "[409.401 333.359 304.95  229.249 268.002 331.9  ]\n",
            "Predicted values:\n",
            "[346.035, 363.402, 336.87199999999996, 236.304, 268.64, 281.42]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxIegx6oRBBj",
        "outputId": "8f06326b-0801-4a24-e038-12b80b17b68c"
      },
      "source": [
        "# Keras Sequantial MLP\n",
        "divorce_model = perform(\"divorce.csv\", \";\", \"Class\",'binary_crossentropy')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "16/16 [==============================] - 16s 3ms/step - loss: 0.7260\n",
            "Epoch 2/4\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.5083\n",
            "Epoch 3/4\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4119\n",
            "Epoch 4/4\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.3646\n",
            "2/2 [==============================] - 1s 5ms/step - loss: 0.3281\n",
            "Accuracy is  0.3280900716781616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VXM1aeGRD8H",
        "outputId": "ab2cbd5c-b40c-445e-f1ab-2af942ac166c"
      },
      "source": [
        "# Keras Sequantial MLP\n",
        "forecast_model = perform(\"forecast.csv\", \";\", \"Target (Total orders)\",'mean_absolute_error')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "6/6 [==============================] - 1s 4ms/step - loss: 299.2990\n",
            "Epoch 2/4\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 298.5066\n",
            "Epoch 3/4\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 300.0425\n",
            "Epoch 4/4\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 297.7820\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 295.3548\n",
            "Mean Absolute Error is  295.3548278808594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwNbOEITRebL"
      },
      "source": [
        "There are the implementation of decision tree by myself.\n",
        "And I used Keras Sequential model for MLP.\n"
      ]
    }
  ]
}